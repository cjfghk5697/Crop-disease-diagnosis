{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ng_COrPEzAd"
      },
      "source": [
        "# 정확도가 안오름\n",
        "\n",
        "그래서 crop된 이미지만 사용하는 방법을 사용하기로 결심."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLmiP0VckTh5",
        "outputId": "57a0039f-c089-4ef4-9d36-d30146dc522f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcE-NvEFnMeh",
        "outputId": "ca607e14-e4a5-4d82-c648-ff5ea7d4a3b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/data\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/data/\"\n",
        "!unzip -q \"/content/drive/MyDrive/data/train.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C69AldJvMvBw",
        "outputId": "dea787e6-91c6-4ac7-ceff-08efcb81d7cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchsampler\n",
            "  Downloading torchsampler-0.1.2-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchsampler) (1.3.5)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from torchsampler) (1.12.0+cu113)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from torchsampler) (4.12.0)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.7/dist-packages (from torchsampler) (0.13.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->torchsampler) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->torchsampler) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->torchsampler) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->torchsampler) (1.21.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->torchsampler) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsampler) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsampler) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torchsampler) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler) (2.10)\n",
            "Installing collected packages: torchsampler\n",
            "Successfully installed torchsampler-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQwABb4aHvJy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU2HqA8XHvJ3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from torchsampler import ImbalancedDatasetSampler\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import glob\n",
        "import utils\n",
        "import numpy\n",
        "import json \n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from autoaugment import ImageNetPolicy, CIFAR10Policy, SVHNPolicy, SubPolicy\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Tuple, Sequence, Callable\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGTtiz-mQmW0",
        "outputId": "211bba14-d0a4-4f55-d13d-dac4036ff811"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'AutoAugment' already exists and is not an empty directory.\n",
            "cp: cannot stat '/content/drive/MyDrive/input/AutoAugment/autoaugment.py': No such file or directory\n",
            "cp: cannot stat '/content/drive/MyDrive/input/AutoAugment/ops.py': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DeepVoltaire/AutoAugment.git\n",
        "!cp /content/drive/MyDrive/input/AutoAugment/autoaugment.py /content/drive/MyDrive/data\n",
        "!cp /content/drive/MyDrive/input/AutoAugment/ops.py /content/drive/MyDrive/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiGpQ-HBKPy2"
      },
      "outputs": [],
      "source": [
        "# 전체 복사\n",
        "for path in glob.glob('/content/drive/MyDrive/data/train/*'):\n",
        "    shutil.copytree(path,f'{path}_focus')\n",
        "#각 파일 포맷들 이름 변경\n",
        "for sample in glob.glob('/content/drive/MyDrive/data/train/*focus/*.csv'):\n",
        "     os.rename(sample,f'{sample[:-4]}_focus.csv')\n",
        "\n",
        "for sample in glob.glob('/content/drive/MyDrive/data/train/*focus/*.json'):\n",
        "     os.rename(sample,f'{sample[:-5]}_focus.json')\n",
        "\n",
        "for sample in glob.glob('/content/drive/MyDrive/data/train/*focus/*.jpg'):\n",
        "     os.rename(sample,f'{sample[:-4]}_focus.jpg')\n",
        "\n",
        "# # 객체 영역만 저장\n",
        "for sample in glob.glob('/content/drive/MyDrive/data/train/*focus'):\n",
        "     img_path = glob.glob(f'{sample}/*.jpg')[0]\n",
        "     sample_image = cv2.imread(img_path)\n",
        "     sample_json = json.load(open(glob.glob(f'{sample}/*.json')[0],'r'))\n",
        "     points = sample_json['annotations']['bbox'][0]\n",
        "     x= int(points['x'])\n",
        "     y= int(points['y'])\n",
        "     w= int(points['w'])\n",
        "     h= int(points['h'])\n",
        "     crop_focus = sample_image[y:y+h,x:x+w,:].copy()\n",
        "     cv2.imwrite(img_path,crop_focus)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIN7yUAHHvJ1"
      },
      "source": [
        "# 사용 패키지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwwhQ-Q0HvJ8"
      },
      "source": [
        "# 데이터 로드\n",
        "\n",
        "## 환경 데이터 통계량 계산 for MinMax Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohpac__EHvJ8",
        "outputId": "1e2f8314-82aa-4390-f8f1-fe1c02709891"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 11533/11533 [02:13<00:00, 86.68it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'내부 습도 1 최고': [25.9, 100.0],\n",
              " '내부 습도 1 최저': [0.0, 100.0],\n",
              " '내부 습도 1 평균': [23.7, 100.0],\n",
              " '내부 온도 1 최고': [3.4, 47.6],\n",
              " '내부 온도 1 최저': [3.3, 47.0],\n",
              " '내부 온도 1 평균': [3.4, 47.3],\n",
              " '내부 이슬점 최고': [0.2, 34.7],\n",
              " '내부 이슬점 최저': [0.0, 34.4],\n",
              " '내부 이슬점 평균': [0.1, 34.5]}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 분석에 사용할 feature 선택\n",
        "csv_features = ['내부 온도 1 평균', '내부 온도 1 최고', '내부 온도 1 최저', '내부 습도 1 평균', '내부 습도 1 최고', \n",
        "                '내부 습도 1 최저', '내부 이슬점 평균', '내부 이슬점 최고', '내부 이슬점 최저']\n",
        "\n",
        "csv_files = sorted(glob.glob('/content/drive/MyDrive/data/train/*/*.csv'))\n",
        "\n",
        "temp_csv = pd.read_csv(csv_files[0])[csv_features]\n",
        "max_arr, min_arr = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
        "\n",
        "# feature 별 최대값, 최솟값 계산\n",
        "for csv in tqdm(csv_files[1:]):\n",
        "    temp_csv = pd.read_csv(csv)[csv_features]\n",
        "    temp_csv = temp_csv.replace('-',np.nan).dropna()\n",
        "    if len(temp_csv) == 0:\n",
        "        continue\n",
        "    temp_csv = temp_csv.astype(float)\n",
        "    temp_max, temp_min = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
        "    max_arr = np.max([max_arr,temp_max], axis=0)\n",
        "    min_arr = np.min([min_arr,temp_min], axis=0)\n",
        "\n",
        "# feature 별 최대값, 최솟값 dictionary 생성\n",
        "csv_feature_dict = {csv_features[i]:[min_arr[i], max_arr[i]] for i in range(len(csv_features))}\n",
        "csv_feature_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJwRX8KDHvJ9"
      },
      "source": [
        "## CustomDataset 제작"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZmafqxFHvJ9"
      },
      "outputs": [],
      "source": [
        "# 변수 설명 csv 파일 참조\n",
        "crop = {'1':'딸기','2':'토마토','3':'파프리카','4':'오이','5':'고추','6':'시설포도'}\n",
        "disease = {'1':{'a1':'딸기잿빛곰팡이병','a2':'딸기흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
        "           '2':{'a5':'토마토흰가루병','a6':'토마토잿빛곰팡이병','b2':'열과','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
        "           '3':{'a9':'파프리카흰가루병','a10':'파프리카잘록병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
        "           '4':{'a3':'오이노균병','a4':'오이흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
        "           '5':{'a7':'고추탄저병','a8':'고추흰가루병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
        "           '6':{'a11':'시설포도탄저병','a12':'시설포도노균병','b4':'일소피해','b5':'축과병'}}\n",
        "risk = {'1':'초기','2':'중기','3':'말기'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cA_7CU0HvJ-",
        "outputId": "3314ece3-861a-48ca-b1b3-d303bb2bd10e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('1_00_0', '딸기_정상'),\n",
              " ('1_a1_1', '딸기_딸기잿빛곰팡이병_초기'),\n",
              " ('1_a1_2', '딸기_딸기잿빛곰팡이병_중기'),\n",
              " ('1_a1_3', '딸기_딸기잿빛곰팡이병_말기'),\n",
              " ('1_a2_1', '딸기_딸기흰가루병_초기'),\n",
              " ('1_a2_2', '딸기_딸기흰가루병_중기'),\n",
              " ('1_a2_3', '딸기_딸기흰가루병_말기'),\n",
              " ('1_b1_1', '딸기_냉해피해_초기'),\n",
              " ('1_b1_2', '딸기_냉해피해_중기'),\n",
              " ('1_b1_3', '딸기_냉해피해_말기')]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_description = {}\n",
        "for key, value in disease.items():\n",
        "    label_description[f'{key}_00_0'] = f'{crop[key]}_정상'\n",
        "    for disease_code in value:\n",
        "        for risk_code in risk:\n",
        "            label = f'{key}_{disease_code}_{risk_code}'\n",
        "            label_description[label] = f'{crop[key]}_{disease[key][disease_code]}_{risk[risk_code]}'\n",
        "list(label_description.items())[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "JCLH0hONtSXt",
        "outputId": "bfdfb9e2-0e91-473e-d4d9-2f89175d8014"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n    transforms.RandomHorizontalFlip(p=0.5),\\n    transforms.RandomVerticalFlip(p=0.5),\\n\\n'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transforms_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    ImageNetPolicy(),\n",
        "\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        [0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "transforms_valid = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        [0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "'''\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpQxNlFkHvJ-"
      },
      "outputs": [],
      "source": [
        "label_encoder = {key:idx for idx, key in enumerate(label_description)}\n",
        "label_decoder = {val:key for key, val in label_encoder.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd2fLVqrHvJ_"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, files, labels=None, mode='train', transforms= Sequence[Callable]):\n",
        "        self.mode = mode\n",
        "        self.files = files\n",
        "        self.csv_feature_dict = csv_feature_dict\n",
        "        self.csv_feature_check = [0]*len(self.files)\n",
        "        self.csv_features = [None]*len(self.files)\n",
        "        self.max_len = 24 * 6\n",
        "        self.label_encoder = label_encoder\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        file = self.files[i]\n",
        "        file_name = file.split('/')[-1]\n",
        "        \n",
        "        # csv\n",
        "        if self.csv_feature_check[i] == 0:\n",
        "            csv_path = f'{file}/{file_name}.csv'\n",
        "            df = pd.read_csv(csv_path)[self.csv_feature_dict.keys()]\n",
        "            df = df.replace('-', 0)\n",
        "            # MinMax scaling\n",
        "            for col in df.columns:\n",
        "                df[col] = df[col].astype(float) - self.csv_feature_dict[col][0]\n",
        "                df[col] = df[col] / (self.csv_feature_dict[col][1]-self.csv_feature_dict[col][0])\n",
        "            # zero padding\n",
        "            pad = np.zeros((self.max_len, len(df.columns)))\n",
        "            length = min(self.max_len, len(df))\n",
        "            pad[-length:] = df.to_numpy()[-length:]\n",
        "            # transpose to sequential data\n",
        "            csv_feature = pad.T\n",
        "            self.csv_features[i] = csv_feature\n",
        "            self.csv_feature_check[i] = 1\n",
        "        else:\n",
        "            csv_feature = self.csv_features[i]\n",
        "        \n",
        "        # image\n",
        "        image_path = f'{file}/{file_name}.jpg'\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_AREA)\n",
        "        img = Image.fromarray(img) # NumPy array to PIL image\n",
        "        if self.transforms is not None:\n",
        "          img = self.transforms(img)\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            json_path = f'{file}/{file_name}.json'\n",
        "            with open(json_path, 'r') as f:\n",
        "                json_file = json.load(f)\n",
        "            \n",
        "            crop = json_file['annotations']['crop']\n",
        "            disease = json_file['annotations']['disease']\n",
        "            risk = json_file['annotations']['risk']\n",
        "            label = f'{crop}_{disease}_{risk}'\n",
        "            \n",
        "            return {\n",
        "                'img' : img.clone().detach(),\n",
        "                'csv_feature' : torch.tensor(csv_feature, dtype=torch.float32),\n",
        "                'label' : torch.tensor(self.label_encoder[label], dtype=torch.long)\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'img' : img.clone().detach(),\n",
        "                'csv_feature' : torch.tensor(csv_feature, dtype=torch.float32)\n",
        "            }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP6iUnjrHvJ_"
      },
      "source": [
        "# 하이퍼파라미터 및 변수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kj_o9HrnHvJ_"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "batch_size = 128\n",
        "class_n = len(label_encoder)\n",
        "learning_rate = 1e-4\n",
        "# 1e-4 2e-4 1e-3 2e-3\n",
        "embedding_dim = 512\n",
        "num_features = len(csv_feature_dict)\n",
        "max_len = 24*6\n",
        "dropout_rate = 0.1\n",
        "epochs = 50\n",
        "vision_pretrain = True\n",
        "save_path = 'best_model.pt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP531Fr1HvJ_"
      },
      "source": [
        "# 데이터셋 구성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SqN42ulnrna"
      },
      "outputs": [],
      "source": [
        "train_focus = [path for path in sorted(glob.glob('/content/drive/MyDrive/data/train/*')) if path.endswith('focus')]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0ETQjOZHvKA"
      },
      "outputs": [],
      "source": [
        "train_origin = [path for path in sorted(glob.glob('/content/drive/MyDrive/data/train/*')) if not path.endswith('focus')]\n",
        "\n",
        "labelsss = pd.read_csv('/content/drive/MyDrive/data/train.csv')['label']\n",
        "train, val = train_test_split(train_origin, test_size=0.2, stratify=labelsss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9j621NNnxkM"
      },
      "outputs": [],
      "source": [
        "train=train+train_focus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qtIqFWpHvKA"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_dataset = CustomDataset(train,transforms=transforms_train)\n",
        "val_dataset = CustomDataset(val,transforms=transforms_valid)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "                      train_dataset,\n",
        "                      pin_memory=True,    \n",
        "                      batch_size=batch_size, \n",
        "                      num_workers=4, \n",
        "                      shuffle=True)\n",
        "\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset,\n",
        "                                             pin_memory=True,\n",
        "                                             batch_size=batch_size, \n",
        "                                             num_workers=4, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeLweaXNHvKA"
      },
      "source": [
        "# 모델\n",
        "\n",
        "## 이미지 분류 모델 : Resnet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TzT501lHvKA"
      },
      "outputs": [],
      "source": [
        "class CNN_Encoder(nn.Module):\n",
        "    def __init__(self, class_n, rate=0.1):\n",
        "        super(CNN_Encoder, self).__init__()\n",
        "        self.model = models.efficientnet_b2(pretrained=True)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        output = self.model(inputs)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYbEAw5cHvKB"
      },
      "source": [
        "## 시계열 모델 : LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pN6SsMiIHvKB"
      },
      "outputs": [],
      "source": [
        "class RNN_Decoder(nn.Module):\n",
        "    def __init__(self, max_len, embedding_dim, num_features, class_n, rate):\n",
        "        super(RNN_Decoder, self).__init__()\n",
        "        #self.lstm = nn.LSTM(max_len, embedding_dim,num_layers=1)\n",
        "        self.lstm = nn.LSTM(max_len, embedding_dim,num_layers=3,bidirectional=False) #bidirectional 사용, 3층이 가장 최적화\n",
        "\n",
        "        self.rnn_fc = nn.Linear(num_features*embedding_dim, 1000)\n",
        "        self.final_layer = nn.Linear(1000 + 1000, class_n) # resnet out_dim + lstm out_dim\n",
        "        self.dropout = nn.Dropout(rate)\n",
        "\n",
        "    def forward(self, enc_out, dec_inp):\n",
        "        hidden, _ = self.lstm(dec_inp)\n",
        "        hidden = hidden.view(hidden.size(0), -1)\n",
        "        hidden = self.rnn_fc(hidden)\n",
        "        concat = torch.cat([enc_out, hidden], dim=1) # enc_out + hidden \n",
        "        fc_input = concat\n",
        "        output = self.dropout((self.final_layer(fc_input)))\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRGMk9MOHvKB"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "## 앙상블"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkl20GhnHvKB"
      },
      "outputs": [],
      "source": [
        "class CNN2RNN(nn.Module):\n",
        "    def __init__(self, max_len, embedding_dim, num_features, class_n, rate):\n",
        "        super(CNN2RNN, self).__init__()\n",
        "        self.cnn = CNN_Encoder(embedding_dim, rate)\n",
        "        self.rnn = RNN_Decoder(max_len, embedding_dim, num_features, class_n, rate)\n",
        "\n",
        "    def forward(self, img, seq):\n",
        "        cnn_output = self.cnn(img)\n",
        "        output = self.rnn(cnn_output, seq)\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU2-ytQ0HvKB",
        "outputId": "e683849e-9b4d-4b39-fd20-479644df7280"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=EfficientNet_B2_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "model = CNN2RNN(max_len=max_len, embedding_dim=embedding_dim, num_features=num_features, class_n=class_n, rate=dropout_rate)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OId3a29OHvKB"
      },
      "source": [
        "# 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g54vAjzTHvKC"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "use_amp = True\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stRl3QvZHvKC"
      },
      "outputs": [],
      "source": [
        "\n",
        "def accuracy_function(real, pred):    \n",
        "    real = real.cpu()\n",
        "    pred = torch.argmax(pred, dim=1).cpu()\n",
        "    score = f1_score(real, pred, average='macro')\n",
        "    return score\n",
        "\"\"\"\n",
        "def train_step(batch_item, training):\n",
        "    img = batch_item['img'].to(device)\n",
        "    csv_feature = batch_item['csv_feature'].to(device)\n",
        "    label = batch_item['label'].to(device)\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    with torch.cuda.amp.autocast():\n",
        "      output = model(img, csv_feature)\n",
        "      loss = criterion(output, label)\n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "    score = accuracy_function(label, output)\n",
        "        \n",
        "    return loss, score\n",
        "\"\"\"\n",
        "def train_step(batch_item, training):\n",
        "\n",
        "    img = batch_item['img'].to(device)\n",
        "    csv_feature = batch_item['csv_feature'].to(device)\n",
        "    label = batch_item['label'].to(device)\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    with torch.cuda.amp.autocast():\n",
        "\n",
        "      if BETA > 0 and np.random.random()>0.5: # cutmix 작동될 확률      \n",
        "        lam = np.random.beta(BETA, BETA)\n",
        "        rand_index = torch.randperm(img.size()[0]).to(device)\n",
        "        target_a = label\n",
        "        target_b = label[rand_index]            \n",
        "        bbx1, bby1, bbx2, bby2 = utils.rand_bbox(img.size(), lam)\n",
        "        img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
        "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
        "        output = model(img,csv_feature)\n",
        "        loss = criterion(output, target_a) * lam + criterion(output, target_b) * (1. - lam)\n",
        "\n",
        "      else:\n",
        "        output = model(img, csv_feature)\n",
        "        loss = criterion(output, label)\n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "    score = accuracy_function(label, output)\n",
        "        \n",
        "    return loss, score\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3VljaB6QHvKC"
      },
      "outputs": [],
      "source": [
        "\n",
        "loss_plot, val_loss_plot = [], []\n",
        "metric_plot, val_metric_plot = [], []\n",
        "BETA=1.0\n",
        "for epoch in range(epochs):\n",
        "    total_loss, total_val_loss = 0, 0\n",
        "    total_acc, total_val_acc = 0, 0\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
        "    training = True\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss, batch_acc = train_step(batch_item, training)\n",
        "        total_loss += batch_loss\n",
        "        total_acc += batch_acc\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Mean Loss' : '{:06f}'.format(total_loss/(batch+1)),\n",
        "            'Mean F-1' : '{:06f}'.format(total_acc/(batch+1))\n",
        "        })\n",
        "    loss_plot.append(total_loss/(batch+1))\n",
        "    metric_plot.append(total_acc/(batch+1))\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
        "    training = False\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss, batch_acc = train_step(batch_item, training)\n",
        "        total_val_loss += batch_loss\n",
        "        total_val_acc += batch_acc\n",
        "  \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Mean Val Loss' : '{:06f}'.format(total_val_loss/(batch+1)),\n",
        "            'Mean Val F-1' : '{:06f}'.format(total_val_acc/(batch+1))\n",
        "        })\n",
        "    val_loss_plot.append(total_val_loss/(batch+1))\n",
        "    val_metric_plot.append(total_val_acc/(batch+1))\n",
        "    \n",
        "    if np.max(val_metric_plot) == val_metric_plot[-1]:\n",
        "        torch.save(model.state_dict(), save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DqK6_e8VWNK7"
      },
      "outputs": [],
      "source": [
        "\n",
        "val_loss_plot= list(t.cpu().detach().numpy() for t in val_loss_plot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Cy1chlzjU6or"
      },
      "outputs": [],
      "source": [
        "loss_plot = list(t.cpu().detach().numpy() for t in loss_plot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6BcwHRFytinO"
      },
      "outputs": [],
      "source": [
        "utils.show_plot(x=loss_plot,y=val_loss_plot,xlabel='epoch',ylabel='loss',title='Loss',plot_label_1='train_loss',plot_label_2='val_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XyT9FLN9CGHE"
      },
      "outputs": [],
      "source": [
        "utils.show_plot(x=metric_plot,y=val_metric_plot,xlabel='epoch',ylabel='metric',title='F-1',plot_label_1='train_metric',plot_label_2='val_metric')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "train.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "8207dccf39e710c758db0a3115e8b6364f9af698460a2f758c1d8836f75fc2ad"
    },
    "kernelspec": {
      "display_name": "eunil_py38",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}