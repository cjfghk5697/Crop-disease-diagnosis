{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# autoaugment, focus image 적용\n",
        "\n",
        "배경 제거\n",
        "```python\n",
        "# 전체 복사\n",
        "for path in glob.glob('/content/drive/MyDrive/data/train/*'):\n",
        "    shutil.copytree(path,f'{path}_focus')\n",
        "#각 파일 포맷들 이름 변경\n",
        "for sample in glob.glob('/content/drive/MyDrive/data/train/*focus/*.csv'):\n",
        "     os.rename(sample,f'{sample[:-4]}_focus.csv')\n",
        "\n",
        "for sample in glob.glob('/content/drive/MyDrive/data/train/*focus/*.json'):\n",
        "     os.rename(sample,f'{sample[:-5]}_focus.json')\n",
        "\n",
        "for sample in glob.glob('/content/drive/MyDrive/data/train/*focus/*.jpg'):\n",
        "     os.rename(sample,f'{sample[:-4]}_focus.jpg')\n",
        "\n",
        "# # 객체 영역만 저장\n",
        "for sample in glob.glob('/content/drive/MyDrive/data/train/*focus'):\n",
        "     img_path = glob.glob(f'{sample}/*.jpg')[0]\n",
        "     sample_image = cv2.imread(img_path)\n",
        "     sample_json = json.load(open(glob.glob(f'{sample}/*.json')[0],'r'))\n",
        "     points = sample_json['annotations']['bbox'][0]\n",
        "     x= int(points['x'])\n",
        "     y= int(points['y'])\n",
        "     w= int(points['w'])\n",
        "     h= int(points['h'])\n",
        "     crop_focus = sample_image[y:y+h,x:x+w,:].copy()\n",
        "     cv2.imwrite(img_path,crop_focus)\n",
        "```\n"
      ],
      "metadata": {
        "id": "9Ng_COrPEzAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLmiP0VckTh5",
        "outputId": "6455a79d-58a4-42c4-aaa7-f1a529fd46f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/data/\"\n",
        "!unzip -q \"/content/drive/MyDrive/data/train.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcE-NvEFnMeh",
        "outputId": "472698eb-6e7c-4bd3-cda0-17f9cd9c0b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsampler\n"
      ],
      "metadata": {
        "id": "C69AldJvMvBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5beaa252-fcea-4ee6-ab4a-b99a80747312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchsampler\n",
            "  Downloading torchsampler-0.1.2-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from torchsampler) (1.12.0+cu113)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from torchsampler) (4.12.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchsampler) (1.3.5)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.7/dist-packages (from torchsampler) (0.13.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->torchsampler) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->torchsampler) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->torchsampler) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->torchsampler) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->torchsampler) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsampler) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsampler) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torchsampler) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler) (3.0.4)\n",
            "Installing collected packages: torchsampler\n",
            "Successfully installed torchsampler-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQwABb4aHvJy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU2HqA8XHvJ3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from torchsampler import ImbalancedDatasetSampler\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "import os\n",
        "import json \n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from autoaugment import ImageNetPolicy, CIFAR10Policy, SVHNPolicy, SubPolicy\n",
        "import tqdm\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Tuple, Sequence, Callable\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/DeepVoltaire/AutoAugment.git\n",
        "!cp /content/drive/MyDrive/input/AutoAugment/autoaugment.py /content/drive/MyDrive/data\n",
        "!cp /content/drive/MyDrive/input/AutoAugment/ops.py /content/drive/MyDrive/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGTtiz-mQmW0",
        "outputId": "245fb29c-b7b6-4325-aa00-46bb1bef6b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'AutoAugment' already exists and is not an empty directory.\n",
            "cp: cannot stat '/content/drive/MyDrive/input/AutoAugment/autoaugment.py': No such file or directory\n",
            "cp: cannot stat '/content/drive/MyDrive/input/AutoAugment/ops.py': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 복사\n",
        "for path in glob.glob('/content/drive/MyDrive/data/train/*'):\n",
        "    shutil.copytree(path,f'{path}_focus')\n",
        "#각 파일 포맷들 이름 변경\n",
        "for sample in glob.glob('/content/drive/MyDrive/data/train/*focus/*.csv'):\n",
        "     os.rename(sample,f'{sample[:-4]}_focus.csv')\n",
        "\n",
        "for sample in glob.glob('/content/drive/MyDrive/data/train/*focus/*.json'):\n",
        "     os.rename(sample,f'{sample[:-5]}_focus.json')\n",
        "\n",
        "for sample in glob.glob('/content/drive/MyDrive/data/train/*focus/*.jpg'):\n",
        "     os.rename(sample,f'{sample[:-4]}_focus.jpg')\n",
        "\n",
        "# # 객체 영역만 저장\n",
        "for sample in glob.glob('/content/drive/MyDrive/data/train/*focus'):\n",
        "     img_path = glob.glob(f'{sample}/*.jpg')[0]\n",
        "     sample_image = cv2.imread(img_path)\n",
        "     sample_json = json.load(open(glob.glob(f'{sample}/*.json')[0],'r'))\n",
        "     points = sample_json['annotations']['bbox'][0]\n",
        "     x= int(points['x'])\n",
        "     y= int(points['y'])\n",
        "     w= int(points['w'])\n",
        "     h= int(points['h'])\n",
        "     crop_focus = sample_image[y:y+h,x:x+w,:].copy()\n",
        "     cv2.imwrite(img_path,crop_focus)"
      ],
      "metadata": {
        "id": "JiGpQ-HBKPy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIN7yUAHHvJ1"
      },
      "source": [
        "# 사용 패키지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwwhQ-Q0HvJ8"
      },
      "source": [
        "# 데이터 로드\n",
        "\n",
        "## 환경 데이터 통계량 계산 for MinMax Scaling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rZncDuf9fnQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ohpac__EHvJ8"
      },
      "outputs": [],
      "source": [
        "# 분석에 사용할 feature 선택\n",
        "csv_features = ['내부 온도 1 평균', '내부 온도 1 최고', '내부 온도 1 최저', '내부 습도 1 평균', '내부 습도 1 최고', \n",
        "                '내부 습도 1 최저', '내부 이슬점 평균', '내부 이슬점 최고', '내부 이슬점 최저']\n",
        "\n",
        "csv_files = sorted(glob('/content/drive/MyDrive/data/train/*/*.csv'))\n",
        "\n",
        "temp_csv = pd.read_csv(csv_files[0])[csv_features]\n",
        "max_arr, min_arr = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
        "\n",
        "# feature 별 최대값, 최솟값 계산\n",
        "for csv in tqdm(csv_files[1:]):\n",
        "    temp_csv = pd.read_csv(csv)[csv_features]\n",
        "    temp_csv = temp_csv.replace('-',np.nan).dropna()\n",
        "    if len(temp_csv) == 0:\n",
        "        continue\n",
        "    temp_csv = temp_csv.astype(float)\n",
        "    temp_max, temp_min = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
        "    max_arr = np.max([max_arr,temp_max], axis=0)\n",
        "    min_arr = np.min([min_arr,temp_min], axis=0)\n",
        "\n",
        "# feature 별 최대값, 최솟값 dictionary 생성\n",
        "csv_feature_dict = {csv_features[i]:[min_arr[i], max_arr[i]] for i in range(len(csv_features))}\n",
        "csv_feature_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJwRX8KDHvJ9"
      },
      "source": [
        "## CustomDataset 제작"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZmafqxFHvJ9"
      },
      "outputs": [],
      "source": [
        "# 변수 설명 csv 파일 참조\n",
        "crop = {'1':'딸기','2':'토마토','3':'파프리카','4':'오이','5':'고추','6':'시설포도'}\n",
        "disease = {'1':{'a1':'딸기잿빛곰팡이병','a2':'딸기흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
        "           '2':{'a5':'토마토흰가루병','a6':'토마토잿빛곰팡이병','b2':'열과','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
        "           '3':{'a9':'파프리카흰가루병','a10':'파프리카잘록병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
        "           '4':{'a3':'오이노균병','a4':'오이흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
        "           '5':{'a7':'고추탄저병','a8':'고추흰가루병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
        "           '6':{'a11':'시설포도탄저병','a12':'시설포도노균병','b4':'일소피해','b5':'축과병'}}\n",
        "risk = {'1':'초기','2':'중기','3':'말기'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cA_7CU0HvJ-"
      },
      "outputs": [],
      "source": [
        "label_description = {}\n",
        "for key, value in disease.items():\n",
        "    label_description[f'{key}_00_0'] = f'{crop[key]}_정상'\n",
        "    for disease_code in value:\n",
        "        for risk_code in risk:\n",
        "            label = f'{key}_{disease_code}_{risk_code}'\n",
        "            label_description[label] = f'{crop[key]}_{disease[key][disease_code]}_{risk[risk_code]}'\n",
        "list(label_description.items())[:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transforms_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    ImageNetPolicy(),\n",
        "\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        [0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "transforms_valid = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        [0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "'''\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "JCLH0hONtSXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpQxNlFkHvJ-"
      },
      "outputs": [],
      "source": [
        "label_encoder = {key:idx for idx, key in enumerate(label_description)}\n",
        "label_decoder = {val:key for key, val in label_encoder.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd2fLVqrHvJ_"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, files, labels=None, mode='train', transforms= Sequence[Callable]):\n",
        "        self.mode = mode\n",
        "        self.files = files\n",
        "        self.csv_feature_dict = csv_feature_dict\n",
        "        self.csv_feature_check = [0]*len(self.files)\n",
        "        self.csv_features = [None]*len(self.files)\n",
        "        self.max_len = 24 * 6\n",
        "        self.label_encoder = label_encoder\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        file = self.files[i]\n",
        "        file_name = file.split('/')[-1]\n",
        "        \n",
        "        # csv\n",
        "        if self.csv_feature_check[i] == 0:\n",
        "            csv_path = f'{file}/{file_name}.csv'\n",
        "            df = pd.read_csv(csv_path)[self.csv_feature_dict.keys()]\n",
        "            df = df.replace('-', 0)\n",
        "            # MinMax scaling\n",
        "            for col in df.columns:\n",
        "                df[col] = df[col].astype(float) - self.csv_feature_dict[col][0]\n",
        "                df[col] = df[col] / (self.csv_feature_dict[col][1]-self.csv_feature_dict[col][0])\n",
        "            # zero padding\n",
        "            pad = np.zeros((self.max_len, len(df.columns)))\n",
        "            length = min(self.max_len, len(df))\n",
        "            pad[-length:] = df.to_numpy()[-length:]\n",
        "            # transpose to sequential data\n",
        "            csv_feature = pad.T\n",
        "            self.csv_features[i] = csv_feature\n",
        "            self.csv_feature_check[i] = 1\n",
        "        else:\n",
        "            csv_feature = self.csv_features[i]\n",
        "        \n",
        "        # image\n",
        "        image_path = f'{file}/{file_name}.jpg'\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_AREA)\n",
        "        img = Image.fromarray(img) # NumPy array to PIL image\n",
        "        if self.transforms is not None:\n",
        "          img = self.transforms(img)\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            json_path = f'{file}/{file_name}.json'\n",
        "            with open(json_path, 'r') as f:\n",
        "                json_file = json.load(f)\n",
        "            \n",
        "            crop = json_file['annotations']['crop']\n",
        "            disease = json_file['annotations']['disease']\n",
        "            risk = json_file['annotations']['risk']\n",
        "            label = f'{crop}_{disease}_{risk}'\n",
        "            \n",
        "            return {\n",
        "                'img' : img.clone().detach(),\n",
        "                'csv_feature' : torch.tensor(csv_feature, dtype=torch.float32),\n",
        "                'label' : torch.tensor(self.label_encoder[label], dtype=torch.long)\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'img' : img.clone().detach(),\n",
        "                'csv_feature' : torch.tensor(csv_feature, dtype=torch.float32)\n",
        "            }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP6iUnjrHvJ_"
      },
      "source": [
        "# 하이퍼파라미터 및 변수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kj_o9HrnHvJ_"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "batch_size = 128\n",
        "class_n = len(label_encoder)\n",
        "learning_rate = 2e-4\n",
        "# 1e-4 2e-4 1e-3 2e-3\n",
        "embedding_dim = 512\n",
        "num_features = len(csv_feature_dict)\n",
        "max_len = 24*6\n",
        "dropout_rate = 0.1\n",
        "epochs = 10\n",
        "vision_pretrain = True\n",
        "save_path = 'best_model.pt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP531Fr1HvJ_"
      },
      "source": [
        "# 데이터셋 구성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0ETQjOZHvKA"
      },
      "outputs": [],
      "source": [
        "train = sorted(glob('/content/drive/MyDrive/data/train/*'))\n",
        "\n",
        "labelsss = pd.read_csv('/content/drive/MyDrive/data/train.csv')['label']\n",
        "train, val,train_label,val_label = train_test_split(train,labelsss, test_size=0.2, stratify=labelsss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qtIqFWpHvKA"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_dataset = CustomDataset(train,transforms=transforms_train)\n",
        "val_dataset = CustomDataset(val,transforms=transforms_valid)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "                      train_dataset,\n",
        "                      pin_memory=True,    \n",
        "                      batch_size=batch_size, \n",
        "                      num_workers=8, \n",
        "                      shuffle=True)\n",
        "\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset,\n",
        "                                             pin_memory=True,\n",
        "                                             batch_size=batch_size, \n",
        "                                             num_workers=8, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeLweaXNHvKA"
      },
      "source": [
        "# 모델\n",
        "\n",
        "## 이미지 분류 모델 : Resnet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TzT501lHvKA"
      },
      "outputs": [],
      "source": [
        "class CNN_Encoder(nn.Module):\n",
        "    def __init__(self, class_n, rate=0.1):\n",
        "        super(CNN_Encoder, self).__init__()\n",
        "        self.model = models.resnet50(pretrained=True)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        output = self.model(inputs)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYbEAw5cHvKB"
      },
      "source": [
        "## 시계열 모델 : LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pN6SsMiIHvKB"
      },
      "outputs": [],
      "source": [
        "class RNN_Decoder(nn.Module):\n",
        "    def __init__(self, max_len, embedding_dim, num_features, class_n, rate):\n",
        "        super(RNN_Decoder, self).__init__()\n",
        "        self.lstm = nn.LSTM(max_len, embedding_dim,num_layers=1)\n",
        "        #self.lstm = nn.LSTM(max_len, embedding_dim,num_layers=3,bidirectional=True) #bidirectional 사용, 3층이 가장 최적화\n",
        "\n",
        "        self.rnn_fc = nn.Linear(num_features*embedding_dim, 1000)\n",
        "        self.final_layer = nn.Linear(1000 + 1000, class_n) # resnet out_dim + lstm out_dim\n",
        "        self.dropout = nn.Dropout(rate)\n",
        "\n",
        "    def forward(self, enc_out, dec_inp):\n",
        "        hidden, _ = self.lstm(dec_inp)\n",
        "        hidden = hidden.view(hidden.size(0), -1)\n",
        "        hidden = self.rnn_fc(hidden)\n",
        "        concat = torch.cat([enc_out, hidden], dim=1) # enc_out + hidden \n",
        "        fc_input = concat\n",
        "        output = self.dropout((self.final_layer(fc_input)))\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRGMk9MOHvKB"
      },
      "source": [
        "## 앙상블"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkl20GhnHvKB"
      },
      "outputs": [],
      "source": [
        "class CNN2RNN(nn.Module):\n",
        "    def __init__(self, max_len, embedding_dim, num_features, class_n, rate):\n",
        "        super(CNN2RNN, self).__init__()\n",
        "        self.cnn = CNN_Encoder(embedding_dim, rate)\n",
        "        self.rnn = RNN_Decoder(max_len, embedding_dim, num_features, class_n, rate)\n",
        "\n",
        "    def forward(self, img, seq):\n",
        "        cnn_output = self.cnn(img)\n",
        "        output = self.rnn(cnn_output, seq)\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU2-ytQ0HvKB"
      },
      "outputs": [],
      "source": [
        "model = CNN2RNN(max_len=max_len, embedding_dim=embedding_dim, num_features=num_features, class_n=class_n, rate=dropout_rate)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OId3a29OHvKB"
      },
      "source": [
        "# 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g54vAjzTHvKC"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "use_amp = True\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stRl3QvZHvKC"
      },
      "outputs": [],
      "source": [
        "\n",
        "def accuracy_function(real, pred):    \n",
        "    real = real.cpu()\n",
        "    pred = torch.argmax(pred, dim=1).cpu()\n",
        "    score = f1_score(real, pred, average='macro')\n",
        "    return score\n",
        "\n",
        "def train_step(batch_item, training):\n",
        "    img = batch_item['img'].to(device)\n",
        "    csv_feature = batch_item['csv_feature'].to(device)\n",
        "    label = batch_item['label'].to(device)\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    with torch.cuda.amp.autocast():\n",
        "      output = model(img, csv_feature)\n",
        "      loss = criterion(output, label)\n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "    score = accuracy_function(label, output)\n",
        "        \n",
        "    return loss, score\n",
        "\n",
        "# early stopping 유무\n",
        "def valid_step(batch_item, training):\n",
        "    img = batch_item['img'].to(device)\n",
        "    csv_feature = batch_item['csv_feature'].to(device)\n",
        "    label = batch_item['label'].to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(img, csv_feature)\n",
        "        loss = criterion(output, label)\n",
        "    score = accuracy_function(label, output)\n",
        "    \"\"\"    \n",
        "    if early_stopping.early_stop:\n",
        "      print(\"Early stopping\")\n",
        "      break\n",
        "    \"\"\"\n",
        "    return loss, score\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VljaB6QHvKC"
      },
      "outputs": [],
      "source": [
        "\n",
        "loss_plot, val_loss_plot = [], []\n",
        "metric_plot, val_metric_plot = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss, total_val_loss = 0, 0\n",
        "    total_acc, total_val_acc = 0, 0\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
        "    training = True\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss, batch_acc = train_step(batch_item, training)\n",
        "        total_loss += batch_loss\n",
        "        total_acc += batch_acc\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Mean Loss' : '{:06f}'.format(total_loss/(batch+1)),\n",
        "            'Mean F-1' : '{:06f}'.format(total_acc/(batch+1))\n",
        "        })\n",
        "    loss_plot.append(total_loss/(batch+1))\n",
        "    metric_plot.append(total_acc/(batch+1))\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
        "    training = False\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss, batch_acc = train_step(batch_item, training)\n",
        "        total_val_loss += batch_loss\n",
        "        total_val_acc += batch_acc\n",
        "  \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Mean Val Loss' : '{:06f}'.format(total_val_loss/(batch+1)),\n",
        "            'Mean Val F-1' : '{:06f}'.format(total_val_acc/(batch+1))\n",
        "        })\n",
        "    val_loss_plot.append(total_val_loss/(batch+1))\n",
        "    val_metric_plot.append(total_val_acc/(batch+1))\n",
        "    \n",
        "    if np.max(val_metric_plot) == val_metric_plot[-1]:\n",
        "        torch.save(model.state_dict(), save_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy"
      ],
      "metadata": {
        "id": "YSLeAuekUq9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss_plot= list(t.cpu().detach().numpy() for t in val_loss_plot)"
      ],
      "metadata": {
        "id": "DqK6_e8VWNK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_plot = list(t.cpu().detach().numpy() for t in loss_plot)\n"
      ],
      "metadata": {
        "id": "Cy1chlzjU6or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.grid()\n",
        "plt.plot(loss_plot, label='train_loss')\n",
        "plt.plot(val_loss_plot, label='val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title(\"Loss\", fontsize=25)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aDvZsHPqCEc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "plt.grid()\n",
        "plt.plot(metric_plot, label='train_metric')\n",
        "plt.plot(val_metric_plot, label='val_metric')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('metric')\n",
        "plt.title(\"F-1\", fontsize=25)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XyT9FLN9CGHE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "8207dccf39e710c758db0a3115e8b6364f9af698460a2f758c1d8836f75fc2ad"
    },
    "kernelspec": {
      "display_name": "eunil_py38",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}