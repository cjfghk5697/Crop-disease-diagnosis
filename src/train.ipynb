{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ng_COrPEzAd"
      },
      "source": [
        "# 결과 기록\n",
        "* 앙상블 결과 91%가 나왔다. 상위 10% 이내 성적이다.\n",
        "* image size를 높혀 학습하는 건 ram을 많이 차지할 뿐만 아니라 학습 속도도 느려짐(당연한 사실). 그래도 점진적으로 정확도가 오르는 모습을 볼 수 있음. 즉 regularizing이 잘되고 만약 메모리와 시간이 허용된다면 할만한 도전임."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLmiP0VckTh5",
        "outputId": "e7661aca-9828-4363-c91e-d5eea40b0986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcE-NvEFnMeh",
        "outputId": "835e3a9b-cf0e-44b9-ae5d-06095e34a4fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data\n",
            "replace train/10027/10027.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/data/\"\n",
        "!unzip -q \"/content/drive/MyDrive/data/train.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C69AldJvMvBw",
        "outputId": "05b9f71c-54aa-4f94-eece-175e67cdd623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsampler in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from torchsampler) (4.12.0)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.7/dist-packages (from torchsampler) (0.13.0+cu113)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchsampler) (1.3.5)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from torchsampler) (1.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->torchsampler) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->torchsampler) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->torchsampler) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->torchsampler) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->torchsampler) (3.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsampler) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsampler) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torchsampler) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5->torchsampler) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQwABb4aHvJy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU2HqA8XHvJ3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from torchsampler import ImbalancedDatasetSampler\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import glob\n",
        "import utils\n",
        "import numpy\n",
        "import json \n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from utils import CosineAnnealingWarmUpRestarts, EarlyStopping,SAM\n",
        "\n",
        "from autoaugment import ImageNetPolicy, CIFAR10Policy, SVHNPolicy, SubPolicy\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Tuple, Sequence, Callable\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "JiGpQ-HBKPy2",
        "outputId": "6eaa6d59-e6d9-4de4-efc1-3f2cd4f12463"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# 효과 없음\\n# 전체 복사\\nfor path in glob.glob('/content/drive/MyDrive/data/train/*'):\\n    shutil.copytree(path,f'{path}_focus')\\n#각 파일 포맷들 이름 변경\\nfor sample in glob.glob('/content/drive/MyDrive/data/train/*focus/*.csv'):\\n     os.rename(sample,f'{sample[:-4]}_focus.csv')\\n\\nfor sample in glob.glob('/content/drive/MyDrive/data/train/*focus/*.json'):\\n     os.rename(sample,f'{sample[:-5]}_focus.json')\\n\\nfor sample in glob.glob('/content/drive/MyDrive/data/train/*focus/*.jpg'):\\n     os.rename(sample,f'{sample[:-4]}_focus.jpg')\\n\\n# # 객체 영역만 저장\\nfor sample in glob.glob('/content/drive/MyDrive/data/train/*focus'):\\n     img_path = glob.glob(f'{sample}/*.jpg')[0]\\n     sample_image = cv2.imread(img_path)\\n     sample_json = json.load(open(glob.glob(f'{sample}/*.json')[0],'r'))\\n     points = sample_json['annotations']['bbox'][0]\\n     x= int(points['x'])\\n     y= int(points['y'])\\n     w= int(points['w'])\\n     h= int(points['h'])\\n     crop_focus = sample_image[y:y+h,x:x+w,:].copy()\\n     cv2.imwrite(img_path,crop_focus)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "\"\"\"\n",
        "# 효과 없음\n",
        "# 전체 복사\n",
        "for path in glob.glob('/content/drive/MyDrive/data/train/*'):\n",
        "    shutil.copytree(path,f'{path}_focus')\n",
        "#각 파일 포맷들 이름 변경\n",
        "for sample in glob.glob('/content/drive/MyDrive/data/train/*focus/*.csv'):\n",
        "     os.rename(sample,f'{sample[:-4]}_focus.csv')\n",
        "\n",
        "for sample in glob.glob('/content/drive/MyDrive/data/train/*focus/*.json'):\n",
        "     os.rename(sample,f'{sample[:-5]}_focus.json')\n",
        "\n",
        "for sample in glob.glob('/content/drive/MyDrive/data/train/*focus/*.jpg'):\n",
        "     os.rename(sample,f'{sample[:-4]}_focus.jpg')\n",
        "\n",
        "# # 객체 영역만 저장\n",
        "for sample in glob.glob('/content/drive/MyDrive/data/train/*focus'):\n",
        "     img_path = glob.glob(f'{sample}/*.jpg')[0]\n",
        "     sample_image = cv2.imread(img_path)\n",
        "     sample_json = json.load(open(glob.glob(f'{sample}/*.json')[0],'r'))\n",
        "     points = sample_json['annotations']['bbox'][0]\n",
        "     x= int(points['x'])\n",
        "     y= int(points['y'])\n",
        "     w= int(points['w'])\n",
        "     h= int(points['h'])\n",
        "     crop_focus = sample_image[y:y+h,x:x+w,:].copy()\n",
        "     cv2.imwrite(img_path,crop_focus)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIN7yUAHHvJ1"
      },
      "source": [
        "# 사용 패키지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwwhQ-Q0HvJ8"
      },
      "source": [
        "# 데이터 로드\n",
        "\n",
        "## 환경 데이터 통계량 계산 for MinMax Scaling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_files = sorted(glob.glob('/content/drive/MyDrive/data/train/*/*.csv'))\n"
      ],
      "metadata": {
        "id": "2bsYyvSbInLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohpac__EHvJ8",
        "outputId": "ba576e01-a973-4ebc-ea31-944528460c9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5766/5766 [01:03<00:00, 90.65it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'내부 습도 1 최고': [25.9, 100.0],\n",
              " '내부 습도 1 최저': [0.0, 100.0],\n",
              " '내부 습도 1 평균': [23.7, 100.0],\n",
              " '내부 온도 1 최고': [3.4, 47.6],\n",
              " '내부 온도 1 최저': [3.3, 47.0],\n",
              " '내부 온도 1 평균': [3.4, 47.3],\n",
              " '내부 이슬점 최고': [0.2, 34.7],\n",
              " '내부 이슬점 최저': [0.0, 34.4],\n",
              " '내부 이슬점 평균': [0.1, 34.5]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# 분석에 사용할 feature 선택\n",
        "csv_features = ['내부 온도 1 평균', '내부 온도 1 최고', '내부 온도 1 최저', '내부 습도 1 평균', '내부 습도 1 최고', \n",
        "                '내부 습도 1 최저', '내부 이슬점 평균', '내부 이슬점 최고', '내부 이슬점 최저']\n",
        "\n",
        "csv_files = sorted(glob.glob('/content/drive/MyDrive/data/train/*/*.csv'))\n",
        "\n",
        "temp_csv = pd.read_csv(csv_files[0])[csv_features]\n",
        "max_arr, min_arr = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
        "\n",
        "# feature 별 최대값, 최솟값 계산\n",
        "for csv in tqdm(csv_files[1:]):\n",
        "    temp_csv = pd.read_csv(csv)[csv_features]\n",
        "    temp_csv = temp_csv.replace('-',np.nan).dropna()\n",
        "    if len(temp_csv) == 0:\n",
        "        continue\n",
        "    temp_csv = temp_csv.astype(float)\n",
        "    temp_max, temp_min = temp_csv.max().to_numpy(), temp_csv.min().to_numpy()\n",
        "    max_arr = np.max([max_arr,temp_max], axis=0)\n",
        "    min_arr = np.min([min_arr,temp_min], axis=0)\n",
        "\n",
        "# feature 별 최대값, 최솟값 dictionary 생성\n",
        "csv_feature_dict = {csv_features[i]:[min_arr[i], max_arr[i]] for i in range(len(csv_features))}\n",
        "csv_feature_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJwRX8KDHvJ9"
      },
      "source": [
        "## CustomDataset 제작"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZmafqxFHvJ9"
      },
      "outputs": [],
      "source": [
        "# 변수 설명 csv 파일 참조\n",
        "crop = {'1':'딸기','2':'토마토','3':'파프리카','4':'오이','5':'고추','6':'시설포도'}\n",
        "disease = {'1':{'a1':'딸기잿빛곰팡이병','a2':'딸기흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
        "           '2':{'a5':'토마토흰가루병','a6':'토마토잿빛곰팡이병','b2':'열과','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
        "           '3':{'a9':'파프리카흰가루병','a10':'파프리카잘록병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
        "           '4':{'a3':'오이노균병','a4':'오이흰가루병','b1':'냉해피해','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
        "           '5':{'a7':'고추탄저병','a8':'고추흰가루병','b3':'칼슘결핍','b6':'다량원소결핍 (N)','b7':'다량원소결핍 (P)','b8':'다량원소결핍 (K)'},\n",
        "           '6':{'a11':'시설포도탄저병','a12':'시설포도노균병','b4':'일소피해','b5':'축과병'}}\n",
        "risk = {'1':'초기','2':'중기','3':'말기'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cA_7CU0HvJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33ce97ef-02fa-4376-8ede-0ec83390cf9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1_00_0', '딸기_정상'),\n",
              " ('1_a1_1', '딸기_딸기잿빛곰팡이병_초기'),\n",
              " ('1_a1_2', '딸기_딸기잿빛곰팡이병_중기'),\n",
              " ('1_a1_3', '딸기_딸기잿빛곰팡이병_말기'),\n",
              " ('1_a2_1', '딸기_딸기흰가루병_초기'),\n",
              " ('1_a2_2', '딸기_딸기흰가루병_중기'),\n",
              " ('1_a2_3', '딸기_딸기흰가루병_말기'),\n",
              " ('1_b1_1', '딸기_냉해피해_초기'),\n",
              " ('1_b1_2', '딸기_냉해피해_중기'),\n",
              " ('1_b1_3', '딸기_냉해피해_말기')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "label_description = {}\n",
        "for key, value in disease.items():\n",
        "    label_description[f'{key}_00_0'] = f'{crop[key]}_정상'\n",
        "    for disease_code in value:\n",
        "        for risk_code in risk:\n",
        "            label = f'{key}_{disease_code}_{risk_code}'\n",
        "            label_description[label] = f'{crop[key]}_{disease[key][disease_code]}_{risk[risk_code]}'\n",
        "list(label_description.items())[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCLH0hONtSXt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a8f476e8-95de-4349-886d-51d10fe61a6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    transforms.RandomHorizontalFlip(p=0.5),\\n    transforms.RandomVerticalFlip(p=0.5),\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "transforms_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        [0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "transforms_valid = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        [0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "'''\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpQxNlFkHvJ-"
      },
      "outputs": [],
      "source": [
        "label_encoder = {key:idx for idx, key in enumerate(label_description)}\n",
        "label_decoder = {val:key for key, val in label_encoder.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd2fLVqrHvJ_"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, files, labels=None, mode='train', transforms= Sequence[Callable]):\n",
        "        self.mode = mode\n",
        "        self.files = files\n",
        "        self.csv_feature_dict = csv_feature_dict\n",
        "        self.csv_feature_check = [0]*len(self.files)\n",
        "        self.csv_features = [None]*len(self.files)\n",
        "        self.max_len = 24 * 6\n",
        "        self.label_encoder = label_encoder\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        file = self.files[i]\n",
        "        file_name = file.split('/')[-1]\n",
        "        \n",
        "        # csv\n",
        "        if self.csv_feature_check[i] == 0:\n",
        "            csv_path = f'{file}/{file_name}.csv'\n",
        "            df = pd.read_csv(csv_path)[self.csv_feature_dict.keys()]\n",
        "            df = df.replace('-', 0)\n",
        "            # MinMax scaling\n",
        "            for col in df.columns:\n",
        "                df[col] = df[col].astype(float) - self.csv_feature_dict[col][0]\n",
        "                df[col] = df[col] / (self.csv_feature_dict[col][1]-self.csv_feature_dict[col][0])\n",
        "            # zero padding\n",
        "            pad = np.zeros((self.max_len, len(df.columns)))\n",
        "            length = min(self.max_len, len(df))\n",
        "            pad[-length:] = df.to_numpy()[-length:]\n",
        "            # transpose to sequential data\n",
        "            csv_feature = pad.T\n",
        "            self.csv_features[i] = csv_feature\n",
        "            self.csv_feature_check[i] = 1\n",
        "        else:\n",
        "            csv_feature = self.csv_features[i]\n",
        "        \n",
        "        # image\n",
        "        image_path = f'{file}/{file_name}.jpg'\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.resize(img, dsize=(512, 512), interpolation=cv2.INTER_AREA) # 원래 256 256 근데 image size를 늘려 점수 올리기\n",
        "        img = Image.fromarray(img) # NumPy array to PIL image\n",
        "        if self.transforms is not None:\n",
        "          img = self.transforms(img)\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            json_path = f'{file}/{file_name}.json'\n",
        "            with open(json_path, 'r') as f:\n",
        "                json_file = json.load(f)\n",
        "            \n",
        "            crop = json_file['annotations']['crop']\n",
        "            disease = json_file['annotations']['disease']\n",
        "            risk = json_file['annotations']['risk']\n",
        "            label = f'{crop}_{disease}_{risk}'\n",
        "            \n",
        "            return {\n",
        "                'img' : img.clone().detach(),\n",
        "                'csv_feature' : torch.tensor(csv_feature, dtype=torch.float32),\n",
        "                'label' : torch.tensor(self.label_encoder[label], dtype=torch.long)\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'img' : img.clone().detach(),\n",
        "                'csv_feature' : torch.tensor(csv_feature, dtype=torch.float32)\n",
        "            }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP6iUnjrHvJ_"
      },
      "source": [
        "# 하이퍼파라미터 및 변수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kj_o9HrnHvJ_"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "batch_size = 8\n",
        "class_n = len(label_encoder)\n",
        "learning_rate = 1e-4\n",
        "# 1e-4 2e-4 1e-3 2e-3\n",
        "embedding_dim = 512\n",
        "num_features = len(csv_feature_dict)\n",
        "max_len = 24*6\n",
        "dropout_rate = 0.1\n",
        "epochs = 50\n",
        "vision_pretrain = True\n",
        "save_path = 'best_model.pt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP531Fr1HvJ_"
      },
      "source": [
        "# 데이터셋 구성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SqN42ulnrna"
      },
      "outputs": [],
      "source": [
        "#train_focus = [path for path in sorted(glob.glob('/content/drive/MyDrive/data/train/*')) if path.endswith('focus')]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0ETQjOZHvKA"
      },
      "outputs": [],
      "source": [
        "train_origin = [path for path in sorted(glob.glob('/content/drive/MyDrive/data/train/*')) if not path.endswith('focus')]\n",
        "\n",
        "labelsss = pd.read_csv('/content/drive/MyDrive/data/train.csv')['label']\n",
        "train, val = train_test_split(train_origin, test_size=0.2, stratify=labelsss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qtIqFWpHvKA"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_dataset = CustomDataset(train,transforms=transforms_train)\n",
        "val_dataset = CustomDataset(val,transforms=transforms_valid)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "                      train_dataset,\n",
        "                      pin_memory=True,    \n",
        "                      batch_size=batch_size, \n",
        "                      num_workers=4, \n",
        "                      shuffle=True)\n",
        "\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset,\n",
        "                                             pin_memory=True,\n",
        "                                             batch_size=batch_size, \n",
        "                                             num_workers=4, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TzT501lHvKA"
      },
      "outputs": [],
      "source": [
        "class CNN_Encoder(nn.Module):\n",
        "    def __init__(self, class_n, rate=0.1):\n",
        "        super(CNN_Encoder, self).__init__()\n",
        "        self.model = models.densenet201(pretrained=True)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        output = self.model(inputs)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pN6SsMiIHvKB"
      },
      "outputs": [],
      "source": [
        "class RNN_Decoder(nn.Module):\n",
        "    def __init__(self, max_len, embedding_dim, num_features, class_n, rate):\n",
        "        super(RNN_Decoder, self).__init__()\n",
        "        #self.lstm = nn.LSTM(max_len, embedding_dim,num_layers=1)\n",
        "        self.lstm = nn.LSTM(max_len, embedding_dim,num_layers=1,bidirectional=False) #bidirectional 사용, 3층이 가장 최적화\n",
        "\n",
        "        self.rnn_fc = nn.Linear(num_features*embedding_dim, 1000)\n",
        "        self.final_layer = nn.Linear(1000 + 1000, class_n) # resnet out_dim + lstm out_dim\n",
        "        self.dropout = nn.Dropout(rate)\n",
        "\n",
        "    def forward(self, enc_out, dec_inp):\n",
        "        hidden, _ = self.lstm(dec_inp)\n",
        "        hidden = hidden.view(hidden.size(0), -1)\n",
        "        hidden = self.rnn_fc(hidden)\n",
        "        concat = torch.cat([enc_out, hidden], dim=1) # enc_out + hidden \n",
        "        fc_input = concat\n",
        "        output = self.dropout((self.final_layer(fc_input)))\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRGMk9MOHvKB"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "## 앙상블"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkl20GhnHvKB"
      },
      "outputs": [],
      "source": [
        "class CNN2RNN(nn.Module):\n",
        "    def __init__(self, max_len, embedding_dim, num_features, class_n, rate):\n",
        "        super(CNN2RNN, self).__init__()\n",
        "        self.cnn = CNN_Encoder(embedding_dim, rate)\n",
        "        self.rnn = RNN_Decoder(max_len, embedding_dim, num_features, class_n, rate)\n",
        "\n",
        "    def forward(self, img, seq):\n",
        "        cnn_output = self.cnn(img)\n",
        "        output = self.rnn(cnn_output, seq)\n",
        "        \n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU2-ytQ0HvKB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16789be-51e5-4f2a-aa8d-5c0c8bf9c2e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "model = CNN2RNN(max_len=max_len, embedding_dim=embedding_dim, num_features=num_features, class_n=class_n, rate=dropout_rate)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OId3a29OHvKB"
      },
      "source": [
        "# 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g54vAjzTHvKC"
      },
      "outputs": [],
      "source": [
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#base_optimizer = torch.optim.SGD  \n",
        "#optimizer = SAM(model.parameters(), base_optimizer, lr=0.001, momentum=0.9)\n",
        "use_amp = True\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "patience=10\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer,T_max=100, eta_min=0.001)\n",
        "early_stopping = EarlyStopping(patience = patience, verbose = True, path =save_path )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stRl3QvZHvKC"
      },
      "outputs": [],
      "source": [
        "\n",
        "def accuracy_function(real, pred):    \n",
        "    real = real.cpu()\n",
        "    pred = torch.argmax(pred, dim=1).cpu()\n",
        "    score = f1_score(real, pred, average='macro')\n",
        "    return score\n",
        "\"\"\"\n",
        "def train_step(batch_item, training):\n",
        "    img = batch_item['img'].to(device)\n",
        "    csv_feature = batch_item['csv_feature'].to(device)\n",
        "    label = batch_item['label'].to(device)\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    with torch.cuda.amp.autocast():\n",
        "      output = model(img, csv_feature)\n",
        "      loss = criterion(output, label)\n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "    score = accuracy_function(label, output)\n",
        "        \n",
        "    return loss, score\n",
        "\"\"\"\n",
        "def train_step(batch_item, training):\n",
        "\n",
        "    img = batch_item['img'].to(device)\n",
        "    csv_feature = batch_item['csv_feature'].to(device)\n",
        "    label = batch_item['label'].to(device)\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    with torch.cuda.amp.autocast():\n",
        "\n",
        "      if BETA > 0 and np.random.random()>0.5: # cutmix 작동될 확률      \n",
        "        lam = np.random.beta(BETA, BETA)\n",
        "        rand_index = torch.randperm(img.size()[0]).to(device)\n",
        "        target_a = label\n",
        "        target_b = label[rand_index]            \n",
        "        bbx1, bby1, bbx2, bby2 = utils.rand_bbox(img.size(), lam)\n",
        "        img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
        "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
        "        output = model(img,csv_feature)\n",
        "        loss = criterion(output, target_a) * lam + criterion(output, target_b) * (1. - lam)\n",
        "\n",
        "      else:\n",
        "        output = model(img, csv_feature)\n",
        "        loss = criterion(output, label)\n",
        "    \n",
        "    #optimizer.first_step(zero_grad=True)\n",
        "       \n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer)\n",
        "    #optimizer.first_step(zero_grad=True)\n",
        "    #criterion(model(img,csv_feature), label).backward()\n",
        "    #optimizer.second_step(zero_grad=True)\n",
        "    scaler.update()\n",
        "    score = accuracy_function(label, output)\n",
        "        \n",
        "    return loss, score\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VljaB6QHvKC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e8c5a3-769b-4296-c5e7-c17447b47c5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:15,  2.95it/s, Epoch=1, Loss=2.853516, Mean Loss=3.499863, Mean F-1=0.205006]\n",
            "145it [00:49,  2.93it/s, Epoch=1, Val Loss=2.602539, Mean Val Loss=2.716678, Mean Val F-1=0.303434]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (inf --> -0.303434).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:12,  3.00it/s, Epoch=2, Loss=1.357749, Mean Loss=2.394767, Mean F-1=0.338819]\n",
            "145it [00:48,  2.97it/s, Epoch=2, Val Loss=3.944336, Mean Val Loss=2.239172, Mean Val F-1=0.364134]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.303434 --> -0.364134).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:13,  2.98it/s, Epoch=3, Loss=2.017091, Mean Loss=2.098653, Mean F-1=0.375792]\n",
            "145it [00:48,  2.99it/s, Epoch=3, Val Loss=1.921875, Mean Val Loss=1.976545, Mean Val F-1=0.421168]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.364134 --> -0.421168).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:11,  3.01it/s, Epoch=4, Loss=2.086792, Mean Loss=1.930476, Mean F-1=0.411957]\n",
            "145it [00:49,  2.95it/s, Epoch=4, Val Loss=3.276640, Mean Val Loss=1.817941, Mean Val F-1=0.441585]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.421168 --> -0.441585).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:12,  3.00it/s, Epoch=5, Loss=2.177930, Mean Loss=1.818319, Mean F-1=0.445354]\n",
            "145it [00:48,  2.97it/s, Epoch=5, Val Loss=1.863647, Mean Val Loss=1.755917, Mean Val F-1=0.468164]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.441585 --> -0.468164).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:14,  2.96it/s, Epoch=6, Loss=1.753562, Mean Loss=1.735561, Mean F-1=0.470524]\n",
            "145it [00:48,  2.97it/s, Epoch=6, Val Loss=1.797852, Mean Val Loss=1.707195, Mean Val F-1=0.464080]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 1 out of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "577it [03:11,  3.01it/s, Epoch=7, Loss=0.826523, Mean Loss=1.667780, Mean F-1=0.477016]\n",
            "145it [00:48,  2.97it/s, Epoch=7, Val Loss=2.466003, Mean Val Loss=1.589870, Mean Val F-1=0.511765]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.468164 --> -0.511765).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:11,  3.02it/s, Epoch=8, Loss=0.612988, Mean Loss=1.618045, Mean F-1=0.491990]\n",
            "145it [00:48,  2.98it/s, Epoch=8, Val Loss=1.607182, Mean Val Loss=1.634200, Mean Val F-1=0.510520]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 1 out of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "577it [03:11,  3.02it/s, Epoch=9, Loss=2.388618, Mean Loss=1.621996, Mean F-1=0.501745]\n",
            "145it [00:48,  2.97it/s, Epoch=9, Val Loss=3.843750, Mean Val Loss=1.565297, Mean Val F-1=0.497019]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 2 out of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "577it [03:11,  3.02it/s, Epoch=10, Loss=1.601025, Mean Loss=1.559804, Mean F-1=0.520762]\n",
            "145it [00:48,  2.96it/s, Epoch=10, Val Loss=2.842285, Mean Val Loss=1.535114, Mean Val F-1=0.527249]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.511765 --> -0.527249).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:11,  3.02it/s, Epoch=11, Loss=2.184228, Mean Loss=1.482110, Mean F-1=0.538065]\n",
            "145it [00:48,  2.97it/s, Epoch=11, Val Loss=0.682129, Mean Val Loss=1.490867, Mean Val F-1=0.539309]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.527249 --> -0.539309).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:12,  3.00it/s, Epoch=12, Loss=0.791359, Mean Loss=1.474603, Mean F-1=0.540615]\n",
            "145it [00:49,  2.95it/s, Epoch=12, Val Loss=1.245544, Mean Val Loss=1.372687, Mean Val F-1=0.559762]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.539309 --> -0.559762).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:12,  2.99it/s, Epoch=13, Loss=1.739464, Mean Loss=1.448196, Mean F-1=0.545543]\n",
            "145it [00:48,  2.96it/s, Epoch=13, Val Loss=1.513794, Mean Val Loss=1.476500, Mean Val F-1=0.543572]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 1 out of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "577it [03:12,  3.00it/s, Epoch=14, Loss=3.152171, Mean Loss=1.358565, Mean F-1=0.572205]\n",
            "145it [00:49,  2.95it/s, Epoch=14, Val Loss=2.093750, Mean Val Loss=1.387282, Mean Val F-1=0.559780]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.559762 --> -0.559780).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:12,  2.99it/s, Epoch=15, Loss=1.767383, Mean Loss=1.393096, Mean F-1=0.566765]\n",
            "145it [00:48,  2.97it/s, Epoch=15, Val Loss=0.289764, Mean Val Loss=1.327523, Mean Val F-1=0.591226]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.559780 --> -0.591226).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:11,  3.01it/s, Epoch=16, Loss=0.685103, Mean Loss=1.414149, Mean F-1=0.569157]\n",
            "145it [00:48,  2.96it/s, Epoch=16, Val Loss=2.597656, Mean Val Loss=1.344771, Mean Val F-1=0.577700]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 1 out of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "577it [03:11,  3.01it/s, Epoch=17, Loss=0.527264, Mean Loss=1.368220, Mean F-1=0.586880]\n",
            "145it [00:48,  2.97it/s, Epoch=17, Val Loss=3.392578, Mean Val Loss=1.399831, Mean Val F-1=0.544635]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 2 out of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "577it [03:11,  3.01it/s, Epoch=18, Loss=1.576208, Mean Loss=1.299366, Mean F-1=0.582121]\n",
            "145it [00:48,  2.97it/s, Epoch=18, Val Loss=1.172729, Mean Val Loss=1.273671, Mean Val F-1=0.609874]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.591226 --> -0.609874).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:15,  2.95it/s, Epoch=19, Loss=0.356193, Mean Loss=1.305246, Mean F-1=0.583844]\n",
            "145it [00:48,  2.96it/s, Epoch=19, Val Loss=2.552979, Mean Val Loss=1.296683, Mean Val F-1=0.596002]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 1 out of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "577it [03:11,  3.01it/s, Epoch=20, Loss=2.015918, Mean Loss=1.292808, Mean F-1=0.579011]\n",
            "145it [00:49,  2.96it/s, Epoch=20, Val Loss=2.891878, Mean Val Loss=1.282077, Mean Val F-1=0.575965]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 2 out of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "577it [03:12,  3.00it/s, Epoch=21, Loss=0.344424, Mean Loss=1.251365, Mean F-1=0.599442]\n",
            "145it [00:49,  2.96it/s, Epoch=21, Val Loss=0.772095, Mean Val Loss=1.254759, Mean Val F-1=0.588000]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 3 out of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "577it [03:11,  3.01it/s, Epoch=22, Loss=2.075034, Mean Loss=1.186381, Mean F-1=0.621749]\n",
            "145it [00:49,  2.95it/s, Epoch=22, Val Loss=3.981377, Mean Val Loss=1.189695, Mean Val F-1=0.625818]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.609874 --> -0.625818).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:13,  2.99it/s, Epoch=23, Loss=0.212189, Mean Loss=1.184966, Mean F-1=0.616402]\n",
            "145it [00:49,  2.95it/s, Epoch=23, Val Loss=1.632986, Mean Val Loss=1.174578, Mean Val F-1=0.621886]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 1 out of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "577it [03:12,  3.00it/s, Epoch=24, Loss=1.987235, Mean Loss=1.151693, Mean F-1=0.625100]\n",
            "145it [00:49,  2.94it/s, Epoch=24, Val Loss=2.482463, Mean Val Loss=1.278628, Mean Val F-1=0.595396]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 2 out of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "577it [03:12,  3.00it/s, Epoch=25, Loss=0.079266, Mean Loss=1.180314, Mean F-1=0.619895]\n",
            "145it [00:49,  2.94it/s, Epoch=25, Val Loss=1.178848, Mean Val Loss=1.106643, Mean Val F-1=0.626131]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.625818 --> -0.626131).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:12,  3.00it/s, Epoch=26, Loss=2.148191, Mean Loss=1.110901, Mean F-1=0.636969]\n",
            "145it [00:49,  2.95it/s, Epoch=26, Val Loss=0.376831, Mean Val Loss=1.163940, Mean Val F-1=0.628402]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.626131 --> -0.628402).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:14,  2.96it/s, Epoch=27, Loss=0.570087, Mean Loss=1.142683, Mean F-1=0.630284]\n",
            "145it [00:49,  2.95it/s, Epoch=27, Val Loss=2.335938, Mean Val Loss=1.104249, Mean Val F-1=0.639622]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.628402 --> -0.639622).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:13,  2.98it/s, Epoch=28, Loss=1.648517, Mean Loss=1.109813, Mean F-1=0.638233]\n",
            "145it [00:49,  2.93it/s, Epoch=28, Val Loss=4.828125, Mean Val Loss=1.098057, Mean Val F-1=0.629532]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 1 out of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "577it [03:14,  2.96it/s, Epoch=29, Loss=1.333282, Mean Loss=1.071474, Mean F-1=0.637394]\n",
            "145it [00:50,  2.88it/s, Epoch=29, Val Loss=1.867991, Mean Val Loss=1.043065, Mean Val F-1=0.656217]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.639622 --> -0.656217).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:18,  2.91it/s, Epoch=30, Loss=2.204286, Mean Loss=1.063732, Mean F-1=0.649135]\n",
            "145it [00:51,  2.83it/s, Epoch=30, Val Loss=0.283081, Mean Val Loss=1.116527, Mean Val F-1=0.629296]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EarlyStopping counter: 1 out of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "577it [03:20,  2.87it/s, Epoch=31, Loss=1.632513, Mean Loss=1.085515, Mean F-1=0.649458]\n",
            "145it [00:51,  2.79it/s, Epoch=31, Val Loss=1.388733, Mean Val Loss=1.116499, Mean Val F-1=0.665927]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.656217 --> -0.665927).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "577it [03:31,  2.73it/s, Epoch=32, Loss=0.093779, Mean Loss=1.082848, Mean F-1=0.649357]\n",
            "145it [00:52,  2.75it/s, Epoch=32, Val Loss=0.133987, Mean Val Loss=1.060771, Mean Val F-1=0.669486]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss decreased (-0.665927 --> -0.669486).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "215it [01:23,  1.60it/s, Epoch=33, Loss=1.139383, Mean Loss=1.067382, Mean F-1=0.631195]"
          ]
        }
      ],
      "source": [
        "\n",
        "loss_plot, val_loss_plot = [], []\n",
        "metric_plot, val_metric_plot = [], []\n",
        "BETA=1.0\n",
        "for epoch in range(epochs):\n",
        "    total_loss, total_val_loss = 0, 0\n",
        "    total_acc, total_val_acc = 0, 0\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
        "    training = True\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss, batch_acc = train_step(batch_item, training)\n",
        "        total_loss += batch_loss\n",
        "        total_acc += batch_acc\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Mean Loss' : '{:06f}'.format(total_loss/(batch+1)),\n",
        "            'Mean F-1' : '{:06f}'.format(total_acc/(batch+1))\n",
        "        })\n",
        "    loss_plot.append(total_loss/(batch+1))\n",
        "    metric_plot.append(total_acc/(batch+1))\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
        "    training = False\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss, batch_acc = train_step(batch_item, training)\n",
        "        total_val_loss += batch_loss\n",
        "        total_val_acc += batch_acc\n",
        "  \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Mean Val Loss' : '{:06f}'.format(total_val_loss/(batch+1)),\n",
        "            'Mean Val F-1' : '{:06f}'.format(total_val_acc/(batch+1))\n",
        "        })\n",
        "    val_loss_plot.append(total_val_loss/(batch+1))\n",
        "    val_metric_plot.append(total_val_acc/(batch+1))\n",
        "    \n",
        "    \n",
        "    early_stopping(-val_metric_plot[-1], model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "    scheduler.step() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqK6_e8VWNK7"
      },
      "outputs": [],
      "source": [
        "\n",
        "val_loss_plot= list(t.cpu().detach().numpy() for t in val_loss_plot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy1chlzjU6or"
      },
      "outputs": [],
      "source": [
        "loss_plot = list(t.cpu().detach().numpy() for t in loss_plot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BcwHRFytinO"
      },
      "outputs": [],
      "source": [
        "utils.show_plot(x=loss_plot,y=val_loss_plot,xlabel='epoch',ylabel='loss',title='Loss',plot_label_1='train_loss',plot_label_2='val_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyT9FLN9CGHE"
      },
      "outputs": [],
      "source": [
        "utils.show_plot(x=metric_plot,y=val_metric_plot,xlabel='epoch',ylabel='metric',title='F-1',plot_label_1='train_metric',plot_label_2='val_metric')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge5hC6lq-cOP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "train.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "8207dccf39e710c758db0a3115e8b6364f9af698460a2f758c1d8836f75fc2ad"
    },
    "kernelspec": {
      "display_name": "eunil_py38",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}